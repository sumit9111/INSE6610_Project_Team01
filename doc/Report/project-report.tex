\documentclass{easychair}
%\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{graphicx, caption}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tabu}
\usepackage{doc}
\usepackage{makeidx}
\usepackage{multicol}
\usepackage{enumerate}
\usepackage{float}

\usepackage{listings}

%%%%%%%%%%%%%% Self Added %%%%%%%%%%%%%
\graphicspath{{./images/}}
\usepackage[utf8]{inputenc}
% \usepackage[english]{babel}

\usepackage{stfloats}
%\usepackage{rsfso}
\usepackage{amsthm}
\usepackage{color,soul}
\newtheorem{lemma}{Lemma}

\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}}

\makeatletter
\newcommand{\thickhline}{%
    \noalign {\ifnum 0=`}\fi \hrule height 1pt
    \futurelet \reserved@a \@xhline
}
\newcolumntype{"}{@{\hskip\tabcolsep\vrule width 0.2pt\hskip\tabcolsep}}

\usepackage{makecell}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\BibTeX{{\rm B\kern-.05em{\sci\kern-.025emb}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{DFRWS IoT Forensic Challenge (2018-2019)
Evidence Analysis Report}


\author{
\IEEEauthorblockN{Ali Wazzan}
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada }\\

\and
\IEEEauthorblockN{Abbas Olfat}
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada}\\

\and
\IEEEauthorblockN{Ghasem Olfat}
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada }\\

\and
\IEEEauthorblockN{Isa Abubakar}
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada }\\

\and
\IEEEauthorblockN{Meryem Ibnoussina }
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada }\\

\and
\IEEEauthorblockN{Favour Emeakama}
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada }\\

\and
\IEEEauthorblockN{Sumit Kumar}
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada }\\

\and
\IEEEauthorblockN{Parisa Ahmadi}
\IEEEauthorblockA{\textit{CIISE}\\
\textit{Concordia University}\\ Montreal, QC, Canada }\\
}
 


\maketitle
% add page number
\thispagestyle{plain}
\pagestyle{plain}

\begin{abstract}
\textbf{The term of IoT means Internets of Things, they are internet connected devices and networks that are used for the sole purpose of automation and monitoring tasks. Technology is growing rapidly and it has became an essential part of our daily life; everyone owns an IoT device that they use for communication which creates and transmit data. This huge amount of data can be  collected and used in a court of law, and this is done by a digital forensic investigators. In this paper, we take on DFRWS IoT Forensic Challenge 2018-2019 challenge and we use efficient approaches that are effectively used for cyber forensics investigations including cloud data, smart things hub, amazon echo devices and automation devices to tackle this challenge.
\textit{Keywords:} Internet of Things, Digital evidence, Computer forensics, Forensic tools.}
\end{abstract}

%\begin{IEEEkeywords}

%\end{IEEEkeywords}

\section{Introduction}
\label{sect:introduction} This report summarizes the result and process of digital forensic analysis on evidences of DFRWS IoT forensic challenge (2018-2019) scenario.

The report is organized as follows: Chapter 1 presents a general overview of the challenge scenario. Chapter 2 presents the tools used for the forensic analysis and describe them. chapter 3 conduct the forensic analysis and investigate using the tools and the data provided by the Challenger. Chapter 4 summarises the paper and what we learned in the course of the challenge.


\subsection{Description of challenge}
\label{callengescenario} The following is given to us by dfrws:
On 17 May 2018 at 10:40, the police were alerted that an illegal drug lab was invaded and
unsuccessfully set on fire. The police respond promptly, and a forensic team is on scene at 10:45,
including a digital forensic specialist.
The owner the illegal drug lab, Jessie Pinkman, is nowhere to be found. Police interrogate two of
Jessie Pinkman’s known associates: D. Pandana and S. Varga. Pandana and Varga admit having
access to the drug lab’s Wi-Fi network but deny any involvement in the raid. They also say that Jessie
Pinkman’s had the IoT security systems installed because he feared attacks from a rival gang and
that Jessie kept the alarm engaged in “Home” mode whenever he was inside the drug lab.
Within the drug lab the digital forensic specialist observes some IoT devices, including an alarm
system (iSmartAlarm), three cameras (QBee Camera, Nest Camera and Arlo Pro) as well as a smoke
detector (Nest Protect). An Amazon Echo and a Wink Hub are also present.
The digital forensic specialist preserves the diagnostic logs from the iSmartAlarm base station, and
acquires a copy of the file system of the Wink Hub. He also collects the iSmartAlarm and Arlo base
stations to perform an in-depth analysis at the forensic laboratory.
The digital forensic specialist also notices that the a QBee Camera seems to be disabled, so he
collects a sample of the network traffic.
Back at the forensic laboratory, the digital forensic specialist uses the bootloader to collect a memory
image of the two base stations as well as an archive of some folder of interest of the Arlo base station.
Jessie Pinkman's Samsung Galaxy S6 Edge is found at the scene, likely dropped during the raid.
The digital forensic specialist acquires a physical image of this Samsung device.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{Img/Drug Lab.JPG}
    \caption{Drug Lab}
    \label{fig:Drug Lab}
\end{figure}

\subsection{Challenge Questions}
The Attorney General needs answers to the following questions:
\begin{itemize}
    \item At what time was the illegal drug lab raided?
\item Could any of the two friends of Jessie Pinkman have been involved in the raid?
\item If yes: Which friend?
\item What is the confidence in such hypothesis?
\item How was the QBee camera disabled?
\end{itemize}

\section{Forensic Tools}

\label{FA}In this section we will list and describe the tools used to resolve the challenge.


\subsection{Autopsy} Autopsy is a platform for digital forensics and a graphical interface to The Sleuth Kit and other digital forensics instruments. The law enforcement, military, and corporate examiners use it to determine what has happened on a computer. You can even use this free, fast, easy to use application which is able to analyze all types of mobile devices and digital media  \cite{pari_1},\cite{pari_2}
\newline Autopsy is the leading open source web forensics which was designed to be intuitive from the box. Installation is simple, and wizards direct you every step of the way. All findings are displayed in a single tree. \cite{pari_3}
\subsubsection{Provided features } 

\begin{itemize}
	\item Multi-user Cases: Collaborate on large cases with fellow examiners. 
\item Timeline Analysis: Shows system events to help classify activity in a graphical interface. 
\item Keyword Search: Modules searched for text extraction and indexing allow you to find files that reference particular words and find patterns of regular expressions
\item Browser Artifacts: To help distinguish user activity, extracts web data from popular browsers. 
\item Registry Analysis: Uses RegRipper to classify documents and USB devices which have been recently accessed. 
\item LNK File Analysis: identifies short cuts and documents which have been accessed 
\item Email Analysis: Parses messages in MBOX format, like Thunderbird for example.
\item EXIF: Extracts geo location and camera information from JPEG files. 
\item Sorting of File Type: Group files by type to find all images or documents. 
\item Media Playback: Display the application's videos and pictures, which do not need an external screen. 
\item Thumbnail viewer: Shows image thumbnails to help you view images quickly. 
\item Robust analysis of the file system: Support for common file systems like NTFS, FAT12/FAT16/FAT32/ExFAT, HFS+, ISO9660 (CD-ROM), Ext2/Ext3/Ext4, Yaffs2, and UFS from The Sleuth Kit.
\item Hash Set Filtering: Filter out known good files using NSRL and flag known bad files using custom hashsets in HashKeeper, md5sum, and EnCase formats. 
\item Tags: Tag files with arbitrary tag names, such as 'bookmark' or 'suspicious', and add comments.
\item Unicode Strings Extraction: Extracts strings from unallocated space and unknown file types in many languages (Arabic, Chinese, Japanese, etc.).
\item File Type Detection based on signatures and extension mismatch detection.
\item Interesting Files Module will flag files and folders based on name and path.
\item Android Support: Extracts data from SMS, call logs, contacts, Tango, Words with Friends, and more. 
\end{itemize}

\subsubsection{Autopsy Input Formats}
\begin{itemize}

\item Disk images(in raw/dd or E01 format)
\item Local drives
\item Folder of local files
\end{itemize}

\subsubsection{Autopsy Report Formats}

\begin{itemize}
\item HTML
\item Excel
\item Body
\end{itemize}

\subsubsection{Autopsy in our case}
We had different types of data gathered from different devices including the smart phone and base stations. So, we had images which should be browsed and information that should be extracted, and to do so Autopsy was one of our tools.

\subsection{Online Json Tool}
It is a JSON Editor Online used as a web-based tool to view, edit, format, transform all kind of JSON documents.
In our case this tool is used to analyse the JSON logs of iSmartAlarm App to be able to answer the challenge questions.
\subsection{Kibana}
Kibana is an open source data visualization dashboard for Elasticsearch. It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Users can create bar, line and scatter plots, or pie charts and maps on top of large volumes of data. \cite{Ali_4} \cite{Ali_5} \\ In our case we followed TapiocaPearlo solution in using Kibana after running the python code (parse tools) to visualise, order and classify the data by using to make it readable to the human eye. Using Timelion feature, we were able to filter the unwanted time zones by adjusting the time range.
\subsubsection{Features of Kibana}
Kibana offers its users the following features \cite{Mery_1}:

\begin{itemize}
\item Visualization : kibana has several way to virtualize data, the most used ones are : vertical bar chart, horizontal bar chart, pie chart, line graph, heat map etc.
\item Dashboard : After virtualizing data we can place them on one board. Observing different sections together gives us a clear overall idea about what exactly is happening.
\item Dev Tools : We can add dummy indexes from dev tools and also add, update, delete the data and use the indexes to create visualization.
\item Reports : we can convert all the data in the form of visualization and dashboard to reports of CSV format, embedded in the form of URLs to be shared with others.
\item Filters and Search query : We can use the filters and search queries to get the required details for a particular input from a dashboard or visualization tool.
\item Timelion : it is used for time based data analysis. In order to work with timeline, we need to use simple expression language which helps us to perform calculations on the data to obtain the results we are looking for. It also helps to compare the data of the previous cycle in terms of week , month etc.
\end{itemize}

\subsection{DB Browser for SQLite}
DB Browser for SQLite (DB4S) is a high quality, visual, open source tool to create, design, and edit database files compatible with SQLite. In our case, we used this tool to brows the different databases found in Jessie Pinkman's phone,  Table \ref{tab:DB} is the list of the databases found there. Immense amount of data about Jessie was found, most of them were unrelated to the event but some of them lead us to important evidence that can be used in the case and to track Jessie such as his Amazon account ID, which was found in Amazon databases shown in Figure \ref{fig:Amazon Database} or the name of the operator who disarmed the alarm before the raid happens shown in Figure \ref{fig:ISMD}.
\subsection{Tool5}
\subsection{Tool6}


\subsection{Python}
Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. \cite{Ali_1} \\
In our case, python was used on jupyter notebook editor \cite{Ali_2} to use the parse tools developed to retrieves the activity records in the database of the devices.


\subsection{Parser Tools}
The following are tools that were developed and used to extract and retrieve activities and data from databases or video frames from the videos. \cite{Ali_3}
\subsubsection{Wink Activity Parser}
python wink\_activity\_parser.py -d \textless DB path\textgreater to run the tool
\subsubsection{Nest Video Recovery Tool}
python nest\_video\_recovery.py -d \textless DB path\textgreater [-o \textless output path\textgreater] [-m] [-a] [-f] to run the tool.
\subsubsection{iSmartAlarm App Dairy Parser}
python ismartalarm\_dairy\_parser.py -d \textless DB path\textgreater to run the tool.
\subsubsection{Server Stream Parser}
python server\_stream\_parser.py -d \textless DB path\textgreater to run the tool.
\subsubsection{Amazon Alexa CIFT Tool Parser}
python alexa\_cift\_parser.py -d \textless DB path\textgreater -t \textless timezone=’UTC+0200’\textgreater to run the tool.

\subsection{Kibana}
Kibana is an open source data visualization dashboard for Elasticsearch. It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Users can create bar, line and scatter plots, or pie charts and maps on top of large volumes of data. \cite{Ali_4} \cite{Ali_5} \\ In our case we followed TapiocaPearlo solution in using Kibana after running the python code (parse tools) to visualise, order and classify the data by using to make it readable to the human eye. Using Timelion feature, we were able to filter the unwanted time zones by adjusting the time range. 





\section{Forensic Analysis of Data}


\subsection{Pinkman's Samsung}
 \subsubsection{Autopsy Findings}
 The Samsung smart phone data was a compressed file which we extracted it with WinRAR application and found 4 files including “blk0\_{sda.bin}”, “blk16\_sdb.bin”, “blk32\_sdc.bin” and “procdata.zip”. 

\begin{itemize}
\item blk0\_sda.bin: This is the largest file in image containing the all user and applications data.
\item blk16\_sdb.bin: In Autopsy nothing can be found from this file.
\item blk32\_sdc.bin: In Autopsy nothing can be found from this file.
\item procdata.zip: Contains some information about device hardware like phone model, CPU and disk information, some information about file systems, mounting volume and partitions, etc. 
 \end{itemize}
 
 “blk0\_sda.bin” file which was known as an image file in Autopsy, and when we introduced this file as a data source to the application we could gain access to the volumes of the phone and see different file types including images, videos, audios, data bases, archives, etc.
There were 20 volumes, 2 Unallocated volumes and 18 other volumes which their names are mentioned in Table 1.


\begin{table*}
  \centering
    \caption{Volumes detected in the ‘blk0\_sda.bin’ file}
    \label{tab:table1}
    \begin{tabular}{c|c|c|c|c|c} 
      \hline
BOTA0		& BOTA1		& EFS		& PARAM		& BOOT		& CACHE\\
 \hline
RECOVERY	& OTA		& RADIO		& TOMBSTONES	& DNT		& HIDDEN\\
  \hline
PERSISTENT	& STEADY		& PERSDATA	& SBFS		& SYSTEM		& USERDATA\\
  \hline
    \end{tabular}
\end{table*}


\begin{figure}[h]
	\centering
		\includegraphics[width=1.00\textwidth]{autopsy.jpg}
	\caption{Samsung data exploring using Autopsy}
	\label{fig:autopsy}
\end{figure}

By browsing the stored data in these volumes, we could find some useful information in different types including media files (images, screenshots, videos) and databases containing the data of management applications installed on the smart phone related to devices in the lab. 
The extracted traces can be categorized in three categories:
\begin{enumerate}
\item Databases:\\
IoT devices in lab have some applications for managing them installed on the phone and they have some databases, and we could find them in the below mentioned paths.\\
\begin{table}[]

   
\begin{tabular}{|c|c|m{6cm}|}

\hline
Device & Database & Path  \\
\hline
 iSmartAlarm & iSmartAlarm.DB & /data/iSA.common/databases/\\
\hline                    
 Wink Hub & persistenceDB & /data/com.quirky.android.wink.wink /databases/\\
\hline
Nest Protect/Camera & frame\_database & /data/com.nest.android/cache /f315c6e2b5434a5381f1f5be6f73b4b3/ \\
\hline 
Nest Protect/Camera & cache & /data/data/com.nest.android/databases\\
\hline
 Arlo & default.realm & /data/com.netgear.android/files/\\
\hline
Amazon echo & map\_data\_storage\_v2.db	& 	/data/com.amazon.dee.app/databases/\\
\hline 
\end{tabular}
 \caption{Extracted DBs from Smart Phone}
    \label{tab:my_label}
\end{table}
\item Files:\\
In addition to data bases there are some other format of files like XML or json, etc. which may contain some information which we could extract them from the application folder on the smart phone.\\

   
\begin{table}[]
   
\begin{tabular}{|c|m{5cm}|m{6.3cm}|}
\hline
Device & File & path\\
\hline
iSmartAlarm & iSmartAlermData.xml & 	/USERDATA/data/iSA.common
/shared\_prefs/\\
\hline
Wink Hub & wink\_local\_pref\_470654.xml & 	/USERDATA/data/
com.quirky.android.wink.wink
/shared\_prefs/\\
\hline
Wink Hub & user.xml & /USERDATA/data/
com.quirky.android.wink.wink
/shared\_prefs/\\
\hline
Wink Hub & com.quirky.android.wink.wink
\_preferences.xml	& /USERDATA/data
/com.quirky.android.wink.wink
/shared\_prefs/\\
\hline
Nest Protect/Camera	& cache-1332523362.json & /USERDATA/data/com.nest.android
/cache/cache/\\
\hline
Nest Protect/Camera	& com.nest.android.preferences.xml & /USERDATA/data/com.nest.android
/shared\_prefs/\\
\hline
Nest Protect/Camera	& cache-1503821048.json & /USERDATA/data/
com.nest.android/cache/cache/\\
\hline
arlo & Phoenix.xml & /USERDATA/data/com.netgear.android
/shared\_prefs/\\
\hline
QBee Camera & com.vestiacom.qbeecamera
\_preferences.xml & /USERDATA /data/
com.vestiacom. qbeecamera/shared\_prefs\\
\hline
Nest Protect/Camera	& cache-1332523362.json & /USERDATA/data/com.nest.android
/cache/cache/cache-1332523362.json\\
\hline
Amazon echo & service.identity.xml & /USERDATA/data/com.amazon.dee.app
/shared\_prefs/\\
\hline
\end{tabular}
 \caption{Extracted Files from Smart Phone}
   \label{tab:my_label}
\end{table}

\item Media:
The third type of information which was retrieved from the smart phone was the media including both images and videos.\\
\begin{table}[]
\begin{tabular}{|c|c|m{6.3cm}|}							 
\hline
Media owner & Media & path\\
\hline
User & Photographs & /USERDATA/media/0/DCIM/Camera\\
\hline
User & Screenshots & /media/0/DCIM/Screenshots\\
\hline
Nest Cam and Arlo Pro	& JPEG image caches	& /USERDATA/data/
com.quirky.android.wink.wink/cache/
image\_manager\_disk\_cache/\\
\hline
Nest Cam & Cached pictures & /USERDATA/data/
com.nest.android/cache/dcnetwork\\
\hline
Arlo & JPEG image caches & /USERDATA/data/
com.netgear.android/cache/http/\\
\hline
\end{tabular}
 \caption{Extracted Media from Smart Phone}
   \label{tab:my_label}
\end{table}

\textbf{Obtained results and evidences:}\\
Finding from Databases and Files would be analyzed in each device section in following. In media part we could find some pictures taken by the user which were related to IoT devices and could give us some information about those devices like their MAC address or serial numbers. These photographs have been stored in ‘USERDATA/media/0/DCIM/Camera’ path as mentioned in Table 4 and gave us the device specification as mentioned below.\\


\begin{table}[]
\begin{tabular}{|c|c|c|c|}							 
\hline
Pic number	& Device &	Info type &	Info\\
\hline
20180326\_164922.jpg & Arlo Base Station & MAC Address & 08:02:8E:FF:75:4F\\
\hline
20180326\_164922.jpg & Arlo Base Station & Serial Number & 4RD37B75A1EC9\\
\hline
20180410\_091838.jpg & Wink Hub & MAC Address	& B4:79:A7:25:02:FA\\
\hline
20180410\_091838.jpg & Wink Hub & Serial Number & 16170011WZD1\\
\hline
20180410\_091924.jpg & Nest Protect & Network Name & NEST-E345\\
\hline
20180410\_091924.jpg & Nest Protect & Serial Number & 06CA01AC331600CA\\
\hline
20180410\_092015.jpg & iSmartAlarm Base Station & Model Name & iPU3G\\
\hline
20180410\_092015.jpg & iSmartAlarm Base Station & MAC Address & 00:4D:32:09:D9:E4\\
\hline
20180410\_092059.jpg & iSmartAlarm Motion Sensor & Model Name & PIR3G\\
\hline
20180410\_092059.jpg & iSmartAlarm Motion Sensor & Serial Number & 141605015143012\\
\hline
20180410\_092120.jpg & Nest Cam & Model Name & A0005\\
\hline
20180410\_092120.jpg & Nest Cam & MAC Address & 18:B4:30:61:C9:EF\\
\hline
\end{tabular}
 \caption{Obtained Devices Information from Images in Phone}
   \label{tab:my_label}
\end{table}\\
There were also some screenshots taken from the application which gave us some information about other devices:\\

\begin{table}[]
\begin{tabular}{|c|c|c|c|}							 
\hline
Pic number	& Device &	Info type &	Info\\
\hline
Screenshot_20180502-132904.png & QBee camera & MAC Address & D8:FB:5E:E1:01:92 \\
\hline
\end{tabular}
 \caption{Obtained Devices Information from Screenshots in Phone}
   \label{tab:my_label}
\end{table}


\subsection{iSmartAlarm Base Station}

iSmartAlarm is a smart home security device do-it-yourself (DIY), operated with a user's smartphone. iSmartAlarm designs and produces the device and appliances\cite{pari_4}.\\
This systems consists of a CubeOne which is called the brain of the system by the company and customers can add different number of Contact Sensors, Motion Sensor or Remote Tags.Contact Sensors can be placed (battery-operated and attached with double-sided tape) at door or window to make customer sure know when someone enters or leaves\cite{pari_5}.\\   

\textbf{}

\textbf{Obtained result by using Autopsy and DB Browser:}\\
There are some snapshots found in the smartphone which were taken from the iSmartAlarm application and shows that the application can shows the status of “The Cube”, Sensors or Remote tags.

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{Img/Screenshot20180330203354.png}
    \caption{iSmartAlarm screenshot}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{Img/Screenshot20180330203515.png}
    \caption{iSmartAlarm sensors' status}
    \label{fig:my_label}
\end{figure}

 Like other IoT devices this solution has an application installed on the smart phone which stored data on databases and some XML files.
 
\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Img/xml.jpg}
    \caption{ID and Password stored in iSmartAlarm.xml file}
    \label{fig:my_label}
\end{figure}
\subsubsection{Database}
In the database of the application we found a name by ‘pandadodu’ which was the operator who deactivated the alarm system shortly before the man entered the tabletting room at 10:34 on the day of the incident. The nickname 'pandadodu' is probably a combination of the first and last names of him which is D. Pandana.
\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Img/iSmartAlarm.JPG}
    \caption{Evidence Found in iSmartDatabase Database}
    \label{fig:ISMD}
\end{figure}
 
\subsection{Arlo Base Station}
Arlo Technologies is a company known for home automation, producing wireless surveillance cameras. Before its initial public offering on the New York Stock Exchange in August 2018, Arlo had been considered a brand by Netgear.\\

\textbf{Obtained result by using Autopsy and DB Browser:}\\

Databases:\\
The realm.default is the Arlo database which was on the smart phone in path USERDATA/data/com.netgear.android/files/.\\

Files:\\
The Phoenix.xml which has been found in the USERDATA/data/com.netgear.android/shared\_prefs/ directory contains some information line User Id and the email of the user.
\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Img/phoenix.jpg}
    \caption{phoenix.xml file content}
    \label{fig:my_label}
\end{figure}

\subsection{QBee}
The QBee Camera lets users watch their phone live. When the motion is detected, users can get an alert, watch real-time footage, and sound the built-in siren of the QBee Camera. The QBee Camera reads out the ambient temperature , humidity, light and noise levels with its integrated sensors \cite{pari_6}.\\

\textbf{Obtained result by using Autopsy and DB Browser:}\\

In the /USERDATA/data/com.vestiacom.qbeecamera/shared\_prefs path we can find the com.vestiacom.qbeecamera\_preferences.xml file which contains some encrypted information.\\

\subsection{Wink Hub}
\subsection{Wink Hub}
The Wink Hub allows your vast range of smart products to speak the same wireless language, so you can conveniently monitor them from the Wink app — and customise their interaction\cite{pari_7}.\\
\textbf{Obtained result by using Autopsy:}\\

Databases:\\
Persistence DB in ‘/data/com.quirky.android.wink.wink/databases/’ directory belong to Wink Hub and has 2 table which ‘Elements’ tables contains data about the items and events related to Wink Hub and in json format.\\

Files:\\
The ‘wink\_local\_pref\_470654.xml’ , ‘user.xml’ and ‘com.quirky.android.wink.wink\_preferences.xml’ files in path ‘/USERDATA /data/com.quirky.android.wink.wink/shared\_prefs/’ path respectively contains some information about devices connected to Hub and mobile ID and gmail address.\\

\subsection{Amazon Echo}
Amazon Echo is a hands-free, voice-controlled speaker. To play music, ask questions, make calls, send and receive messages, provide information, news, sports scores, weather, and more, Echo connects to the Alexa Voice Service. Amazon echo is able to use user voice to control compatible smart home devices  such as flipping on the lamp, turning on the coffee maker, or dimming the lights. Echo works with lights, locks, switches, thermostats, and more from WeMo, Philips Hue, ecobee, and Wink\cite{pari_8}.\\

\textbf{Obtained result by using Autopsy and DB Browser:}\\

Databases:\\
map\_data\_storage\_v2.db database located in the ‘USERDATA/data/com.amazon.dee.app/databases/’ path contains an “account” table containing the lab owner account record.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Img/amazon Account.jpg}
    \caption{map\_data\_storage\_v2.db database content}
    \label{fig:my_label}
\end{figure}

Files:\\

The username and the email of owner were found in the service.identity.xml file in ‘/USERDATA /data/com.amazon.dee.app/shared\_prefs/’ directory.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Img/amazon AccountXML.jpg}
    \caption{service.identity.xml file content}
    \label{fig:my_label}
\end{figure}

In PKStorage DB Browser by DB Browser changing the mode of the iSmartAlarm system by the Jessie voice commands was found:\\
\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Img/alexa.jpg}
    \caption{Browsing PKStorage database by DB Browser}
    \label{fig:my_label}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Img/alexa2.jpg}
    \caption{PKStorage database content}
    \label{fig:my_label}
\end{figure}
\subsection{Network}
\subsubsection{Entities}
\subsubsection{Conversation}


\section{Conclusion}
\label{sect:conclusion} Write conclusion here.



\section{Appendix}

\subsection{Figures}
The follow are the figures that supports our report.
\subsubsection{Kibana Data visualisation}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.92\textwidth]{Img/TimeLion.jpg}
    \caption{Data Visualisation Using Timelion}
    \label{fig:Drug Lab}
\end{figure}

\subsection{Codes}
The following are the python codes used to extract and retrieve data.
\subsubsection{Alexa CIFT Database Tool Parser}


\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Alexa CIFT Database Tool Parser}}
\lstset{label={lst:code_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}
from argparse import ArgumentParser
from datetime import datetime, timezone

from utils.logging.log import Log
from utils.database.misc import dict_factory
from utils.time import to_datetime
from utils.elastic import Elastic

import time
import sqlite3
import os


class CIFTDatabaseParser(object):
    """Parser for parse information from cift database."""

    def __init__(self, database, timezone):
        self.database = database
        self.timezone = timezone

    def parse(self):
        """Parse timeline from database."""
        Log.debug("Extracting activities from database...")

        with sqlite3.connect(self.database) as con:
            con.row_factory = dict_factory
            cur = con.cursor()

            cur.execute("SELECT * FROM TIMELINE")
            activities = cur.fetchall()

        documents = []

        for activity in activities:
            documents.append({
                'time': self.convert_time(activity['date'], activity['time']),
                'user': activity['user'],
                'short': activity['short'],
                'desc': activity['desc'],
                'notes': activity['notes']
            })

        Log.info("Successfully parsed data from database.")

        self.save(documents)

    def save(self, documents):
        with Elastic(index='alexa', doc_type='activity') as elastic:
            elastic.upload(documents, 'time')

        Log.info("Successfully uploaded data into elasticsearch.")

    def convert_time(self, date, _time):
        """Convert splited time into datetime."""
        dtime = datetime.strptime(f"{date} {_time} {self.timezone}", "%Y-%m-%d %H:%M:%S.%f %Z%z")
        
        # check timestamp is 0
        if dtime.timestamp() <= 0:
            return to_datetime(0)

        return dtime.astimezone(timezone.utc)\
                    .replace(tzinfo=None)

    def __del__(self):
        del self


def main(args):
    """Main method for parsing activities."""
    if not os.path.exists(args.database):
        Log.error("cift_amazon_alexa.db file not found.", trace_exc=False)
        return

    cdp = CIFTDatabaseParser(args.database, args.timezone)
    cdp.parse()
    del cdp


if __name__ == '__main__':
    parser = ArgumentParser(description="Amazon Alexa CIFT database parser v1.0")
    parser.add_argument("-d", "--database", dest="database", type=str, required=True,
                        help="cift_amazon_alexa.db database file path")
    parser.add_argument("-t", "--timezone", dest="timezone", type=str, required=True,
                        help="Timezone which used at Amazon Alexa. ex) UTC+2 -> UTC+0200")

    args = parser.parse_args()
    main(args)

\end{lstlisting}


    
\subsubsection{iSmartAlarm Dairy Parser}


\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={iSmartAlarm Dairy Parser}}
\lstset{label={lst:code_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}

from argparse import ArgumentParser

from utils.logging.log import Log
from utils.database.misc import dict_factory
from utils.elastic import Elastic
from utils.time import to_datetime

import sqlite3
import os


class DairyParser(object):
    """Parser for generating timeline from iSmartAlarm Application."""

    def __init__(self, database):
        self.database = database  # iSmartAlarm database

    def parse(self):
        """Parse dairies from database."""
        Log.debug("Extracting diaries from database...")

        tables = {
            'CameraDairy': {
                'name': 'TB_CameraDairy',
            },
            'IPUDairy': {
                'name': 'TB_IPUDairy',
            },
            'ISC3Dairy': {
                'name': 'TB_ISC3Dairy',
            },
            'SensorDairy': {
                'name': 'TB_SensorDairy',
            }
        }

        # get dairies from database
        with sqlite3.connect(self.database) as con:
            con.row_factory = dict_factory
            cur = con.cursor()

            for key in tables.keys():
                name = tables[key]['name']
                cur.execute(f"SELECT * FROM {name}")
                tables[key]['data'] = cur.fetchall()

        Log.debug("Successfully parsed data from database.")

        self.save(tables)

    def save(self, tables):
        """Save history into elasticsearch."""
        for key in tables.keys():
            data = tables[key]['data']
            if data:
                for i in range(len(data)):
                    data[i]['date'] = to_datetime(data[i]['date'])

                with Elastic(index=key.lower(), doc_type=key.lower()) as elastic:
                    elastic.upload(data, 'date')
                
                Log.info(f"Successfully uploaded {key} data into elasticsearch.")

    def __del__(self):
        del self


def main(args):
    """Main method for parsing dairies."""
    if not os.path.exists(args.database):
        Log.error("iSmartAlarm.DB file not found.", trace_exc=False)
        return

    dp = DairyParser(args.database)
    dp.parse()
    del dp


if __name__ == '__main__':
    parser = ArgumentParser(description="iSmartAlarm dairy parser v1.0")
    parser.add_argument("-d", "--database", dest="database", type=str, required=True,
                        help="iSmartAlarm.DB database file path")

    args = parser.parse_args()
    main(args)


\end{lstlisting}





\subsubsection{Nest Video Recovery Tool}

\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Nest Video Recovery Tool}}
\lstset{label={lst:code_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}

from argparse import ArgumentParser
from datetime import datetime
from pathlib import Path

from utils.logging.log import Log
from utils.elastic import Elastic
from utils.time import to_datetime

import sqlite3
import os


class VideoExtractor(object):
    """Extractor for recovering video frame from Nest Application."""

    def __init__(self, database, output):
        self.database = database
        self.rawvideos = []  # video file list for convert and merge file
        self.videotimes = {}  # video recording time
        self.output = output  # video and log output directory

        # make directory when directory not exist
        if not os.path.exists(output):
            os.mkdir(output)

    def _gen_filename(self, timestamp):
        return datetime.strftime(
            datetime.utcfromtimestamp(timestamp / 1000 + 7200), "%Y-%m-%d_%H:%M:%S")

    def extract(self, merge, frame, add_timeline):
        """Extract frames from database."""
        Log.debug("Extracting videos from database...")

        if frame:
            with sqlite3.connect(self.database) as con:
                cur = con.cursor()
                cur.execute("SELECT frame_time, gop_start_rowid, sps_bytes, pps_bytes, frame_bytes, chunk_complete FROM frame_raw_data_table")
                rows = cur.fetchall()
            sps_bytes = None
            pps_bytes = None
            videobuf = None
            count = 0

            timestamps_by_video = {}
            frames_by_video = {}

            for frame in rows:
                frame_time, gop_start_rowid, _sps_bytes, _pps_bytes, frame_bytes, chunk_complete = frame

                if gop_start_rowid == -1:
                    # set new sps and pps bytes
                    sps_bytes = _sps_bytes
                    pps_bytes = _pps_bytes
                    videobuf = pps_bytes + sps_bytes + frame_bytes
                    timestamps_by_video[count] = [frame_time]
                else:
                    videobuf = videobuf + frame_bytes
                    timestamps_by_video[count].append(frame_time)

                if chunk_complete == 1:
                    frames_by_video[count] = videobuf
                    sps_bytes = None
                    pps_bytes = None
                    videobuf = None
                    count += 1

            if videobuf:
                frames_by_video[count] = videobuf

            for key in frames_by_video.keys():
                # save h264 file
                with open(os.path.join(self.output, f'{key}.h264'), 'wb') as f:
                    f.write(frames_by_video[key])

                i = 0
                for timestamp in timestamps_by_video[key]:
                    os.system(f'ffmpeg -i {self.output}/{key}.h264 -c:v libx264 -filter:v "select=gte(n\,{i})" -frames:v 1 -f h264 {self.output}/{key}_{i}.h264')
                    os.system(f'ffmpeg -i {self.output}/{key}_{i}.h264 -frames:v 1 -f image2 {self.output}/{self._gen_filename(timestamp)}.png')
                    os.remove(f'{self.output}/{key}_{i}.h264')
                    i += 1

                os.remove(f'{self.output}/{key}.h264')
            Log.info(f"Successfully saved image by frame.")

        else:
            with sqlite3.connect(self.database) as con:
                cur = con.cursor()
                cur.execute("SELECT * FROM frame_raw_data_table")
                rows = cur.fetchall()

            videobuf = ""  # temporary buffer for constructing video
            videoname = ""  # name of video file
            count = 0  # video file counter

            for row in rows:
                if row[4]:
                    if videoname:
                        with open(videoname, "wb") as f:
                            f.write(videobuf)
                        self.rawvideos.append(videoname)

                    videobuf = row[5]
                    videobuf += row[4]
                    videobuf += row[6]

                    videoname = os.path.join(self.output, f"{count}.tmp")
                    self.videotimes[videoname] = [row[0]]

                    count += 1
                else:
                    videobuf = videobuf + row[6]

                    if row[0] not in self.videotimes[videoname]:
                        self.videotimes[videoname].append(row[0])

            if videobuf:
                with open(videoname, "wb") as f:
                    f.write(videobuf)
                self.rawvideos.append(videoname)

            Log.info(f"Successfully extrated {count} video files.")

            self.save(merge)

            documents = []

            for filename in self.videotimes.keys():
                runtime = self.videotimes[filename]
                start, end = to_datetime(runtime[0]), to_datetime(runtime[-1])
                filename = os.path.basename(filename).replace('tmp', 'mp4')

                documents.append({
                    'start_time': start,
                    'end_time': end,
                    'filename': filename
                })

            # write history as file
            with open(os.path.join(self.output, 'video_list.txt'), 'w') as f:
                for document in documents:
                    f.write(f"{document['filename']}: {document['start_time']} - {document['end_time']}\n")

            # upload to elasticsearch for add timeline
            if add_timeline:
                with Elastic(index='nest', doc_type='video') as elastic:
                    elastic.upload(documents, 'start_time')

    def save(self, merge, frame):
        """Convert and save into playable video."""
        Log.info("Converting video file codec format...")

        for video in self.rawvideos:
            os.system(f"ffmpeg -f h264 -r 10 -i {video} -c copy {video.split('.')[0]}.mp4")

            # remove original file
            if os.path.exists(video):
                os.remove(video)

        Log.info("Successfully convert the video file codec.")

        if merge:
            Log.info("Merging videos..")

            videos = '|'.join([video.split('.')[0] + ".mp4" for video in self.rawvideos])
            os.system(f"ffmpeg -f concat -i \"concat:{videos}\" -c copy video.mp4")

            for video in self.rawvideos:
                os.remove(f"{video.split('.')[0]}.mp4")

            Log.info(f"Successfully merged {len(self.rawvideos)} videos.")

    def __del__(self):
        del self

def main(args):
    """Main method for recovering video."""
    # if frame_database file not found
    if not os.path.exists(args.database):
        Log.error("frame_database file not found.", trace_exc=False)
        return

    ve = VideoExtractor(args.database, args.output)
    ve.extract(args.merge, args.frame, args.add_timeline)
    del ve


if __name__ == "__main__":
    parser = ArgumentParser(description="Nest video recovery tool v1.0")
    parser.add_argument("-d", "--database", dest="database", type=str, required=True,
                        help="frame_database file path")
    parser.add_argument("-o", "--output", dest="output", type=str, default="output",
                        help="extracted video output file directory")
    parser.add_argument("-m", "--merge", dest="merge", type=bool, default=False,
                        help="merge all frames extracted from database")
    parser.add_argument("-a", "--add-timeline", dest="add_timeline", type=bool, default=False,
                        help="Add recording history at timeline with filename")
    parser.add_argument("-f", "--frame", dest="frame", type=bool, default=False,
                        help="Save by frame as a image")

    args = parser.parse_args()
    main(args)


\end{lstlisting}

\subsubsection{Server Stream Parser}

\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Server Stream Parser}}
\lstset{label={lst:code_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}

from argparse import ArgumentParser
from collections import namedtuple

from utils.elastic import Elastic
from utils.logging.log import Log
from utils.time import to_datetime

import os
import json
import struct
import sys

class ISADiagnoticsStreamParser:
    def __init__(self, diagnotics_stream):
        try:
            with open(diagnotics_stream, 'rb') as f:
                self.stream = f.read()
        except:
            #alert error. need to logging.
            sys.exit(-1)

    def get_unstructured_log(self):
        self.unstructured_stream_parser(self.stream[0x60000:0xE0000])
        return self.unstructured_log

    def get_sensor_log(self):
        self.sensor_log_stream_parser(self.stream[0xE0000:])
        return self.sensor_log

    def sensor_log_stream_parser(self, stream):
        self.sensor_log = []
        stream = stream.replace(b'\x00', b'')
        stream = stream.split(b'$@')
        for s in stream:
            if not s:
                continue
            _, sign, desc = s.split(b"::")
            if sign == b'ALARMDOOR' or sign == b'ALARMPIR':
                try:
                    data = json.loads(desc)
                    log = self.__sensor_log_repackager(data)
                    self.sensor_log.append(log)
                except:
                    pass

    def unstructured_stream_parser(self, stream):
        self.index = 0
        self.unstructured_log = []
        while True:
            self.log = dict()
            sign = stream.find(b'\x24\x40')
            if sign != -1:
                size = struct.unpack("<L", stream[sign+0x2:sign+0x6])[0]
                parsed_data = stream[sign+0xA:sign+0xA+size]
                parsed_data = parsed_data.split(b'::')
                stream = stream[sign+0xA+size:]
            else:
                break
            self.log.update({
                'idx': self.index,
                'tag1': parsed_data[1][:2].decode(),
                'tag2': parsed_data[1][2:].decode(),
                'size': len(parsed_data[2])
            })
            if len(parsed_data[2]) < 16:
                self.__general_parse(parsed_data[2])
            else:
                self.__isa_parse(parsed_data[2])
            self.__classifier()
            self.unstructured_log.append(self.log)
            self.index += 1

    def __sensor_log_repackager(self, log_data):
        """
            000A8540: Contact Sensor
            0006B4E5: PIR Sensor
        """
        sensors = {
            '000A8540': 'Contact',
            '0006B4E5': 'PIR',
        }
        dt_ = to_datetime(log_data['TS'])
        package = {
            'datetime': dt_,
            'sensor': sensors[log_data['SensorID']],
            'sensor_id': log_data['SensorID'],
            'event': False,
            'siren': False,
            'is_detected': False,
        }
        if log_data['MessageType'] == '0':
            package.update({'event':True})
        if log_data['MessageType'] == '0' and log_data['ModeId'] == '2':
            package.update({'siren':True})
        if log_data['DetectAlarm'] == '1':
            package.update({'is_detected':True})
        return package

    def __unpack_to_update(self, data, labels, unpack_tags):
        pseudo_tag = namedtuple('pseudo_tag', labels)
        structured = pseudo_tag(*struct.unpack(unpack_tags, data))._asdict()
        self.log.update(structured)

    def __isa_parse(self, data):
        data_size = self.log['size'] - 16
        self.__unpack_to_update(data, 'sign type1 type2 type3 data', '<4sLLL'+str(data_size)+'s')
        if self.log['sign'].startswith(b'ISA'):
            self.log.update({'desc': 'isa'})
        else:
            self.log.update({'desc': 'general'})

        self.log.update({'sign': self.log['sign'].decode()})

    def __general_parse(self, data):
        if len(data) % 4 != 0:
            self.log['desc'] = 'dummy'
            return
        self.__unpack_to_update(data, 'type1 type2', '<LL')
        self.log['desc'] = 'general'

    def __classifier(self):
        if self.log['desc'] == 'isa':
            types = [self.log[x] for x in ['type1', 'type2', 'type3']]
            if types == [21, 1, 10]:
                self.log.update({
                    'data_type': 'datetime',
                    'data': to_datetime(self.log['data'])
                })
            else:
                self.log.update({'data_type':'raw'})


def main(args):
    if not os.path.exists(args.server_stream):
        Log.error("server_stream file not exist.")
        return

    Log.info("Start parsing iSmartAlarm diagnotics stream...")

    isap = ISADiagnoticsStreamParser(args.server_stream)
    unstructured_log = isap.get_unstructured_log()
    sensor_log = isap.get_sensor_log()

    with Elastic(index='unstructured_log', doc_type='unstructured_log') as elastic:
        datetime_log = []

        for log in unstructured_log:
            if 'data_type' in log.keys():
                if log['data_type'] == 'datetime':
                    datetime_log.append(log)
        elastic.upload(datetime_log, 'data')

    with Elastic(index='sensor_log', doc_type='sensor_log') as elastic:
        elastic.upload(sensor_log, 'datetime')

    Log.info("Successfully upload server_stream data.")

    del isap


if __name__ == '__main__':
    parser = ArgumentParser(description="iSmartAlarm diagnotics server stream parser")
    parser.add_argument('-s', '--server-stream', type=str,
        help='iSmartAlarm server_stream file path')

    args = parser.parse_args()
    main(args)


\end{lstlisting}

\subsubsection{Wink Activity Parser}

\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Wink Activity Parser}}
\lstset{label={lst:code_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}

from argparse import ArgumentParser

from utils.logging.log import Log
from utils.database.misc import dict_factory
from utils.elastic import Elastic
from utils.time import to_datetime

import sqlite3
import json
import os


class WinkActivityParser(object):
    """Wink database activity parser."""

    def __init__(self, database):
        self.database = database

    def parse(self):
        """Parse activity from database."""
        Log.debug("Extracting activities from database...")

        with sqlite3.connect(self.database) as con:
            con.row_factory = dict_factory
            cur = con.cursor()

            cur.execute("SELECT * FROM Elements WHERE Type='activity'")
            data = cur.fetchall()

        Log.debug("Successfully parsed activities from database.")

        self.save(data)

    def save(self, data):
        """Save activity into elasticsearch."""
        activities = [json.loads(activity['Json']) for activity in data]

        for i in range(len(activities)):
            activities[i]['created_at'] = to_datetime(activities[i]['created_at'])

        with Elastic(index='wink', doc_type='activity') as elastic:
            elastic.upload(activities, 'created_at')

        Log.info("Successfully uploaded wink activity data into elasticsearch.")

    def __del__(self):
        del self


def main(args):
    """Main method for parsing dairies."""
    if not os.path.exists(args.database):
        Log.error("persistenceDB file not found.", trace_exc=False)
        return

    wap = WinkActivityParser(args.database)
    wap.parse()
    del wap


if __name__ == '__main__':
    parser = ArgumentParser(description="Wink Activity parser v1.0")
    parser.add_argument("-d", "--database", dest="database", type=str, required=True,
                        help="persistenceDB database file path")

    args = parser.parse_args()
    main(args)

\end{lstlisting}

\begin{thebibliography}{1}

\bibitem{pari_1}
"Autopsy" [Online]. Available: https://www.sleuthkit.org/autopsy/

\bibitem{pari_2}
"Autopsy Information" [Online]. Available: https://www.autopsy.com/about/

\bibitem{pari_3}
"Autopsy Provided Features " [Online]. Available: https://www.sleuthkit.org/autopsy/features

\bibitem{pari_4}
"iSmartAlarm" [online]. Available:  https://en.wikipedia.org/wiki/ISmartAlarmcite\_note-3

\bibitem{pari_5}
"Sensors" [online]. Available: https://www.ismartalarm.com/devicesl

\bibitem{pari_6}
"QBee FAQ" [online]. Available:  https://qbeecam.com/home.html\#qbee-app

\bibitem{pari_7}
"Wink Hub2" [online]. Available: https://www.wink.com/products/wink-hub/

\bibitem{pari_8}
"What is eho?" [online]. Available:https://www.amazon.ca/Echo-2nd-Generation-speaker-Charcoal/dp/B0749ZSPN7

\bibitem{Ali_1}
"Python" [Online]. Available: https://en.wikipedia.org/wiki/Python\_(programming\_language)

\bibitem{Ali_2}
"Jupytor Notebook" [Online]. Available: https://jupyter.org/

\bibitem{Ali_3}
"Parse Tools" [Online]. Available: https://github.com/philgeun/TapiocaPearlo

\bibitem{Ali_4}
"Kibana Definition" [Online]. Available: https://en.wikipedia.org/wiki/Kibana

\bibitem{Ali_5}
"Elastic" [Online]. Available: https://www.elastic.co/kibana

\bibitem{Mery_1}
"Kibana Features, " [Online]. Available:
https://www.tutorialspoint.com/kibana/kibana_overview.htm


\end{thebibliography}

\end{document}